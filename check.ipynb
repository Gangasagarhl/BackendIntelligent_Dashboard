{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f453ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_318041/1942004796.py:2: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data =  pd.read_csv(\"database/call_connected_issues.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fb7100f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'database/counselling_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdatabase/counselling_data.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m data.columns = data.columns.str.replace(\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m data.columns, data.shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'database/counselling_data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"database/counselling_data.csv\")\n",
    "data.columns = data.columns.str.replace(\" \", \"_\")\n",
    "\n",
    "data.columns, data.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "292a7173",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"databse_preperation_csv.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7dca86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f17ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24157f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "099001ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['info.txt',\n",
       " 'Anonymized_Call_Handle_Data.csv',\n",
       " 'repeated_calls.csv',\n",
       " 'India_State_Boundary.prj',\n",
       " 'India_State_Boundary.sbn',\n",
       " 'INDIA_STATES.geojson',\n",
       " 'Call_not_picked.csv',\n",
       " 'India_State_Boundary.sbx',\n",
       " 'call_connected_issues.csv',\n",
       " 'counselling_data.csv',\n",
       " 'India_State_Boundary.cpg',\n",
       " 'India_State_Boundary.shx',\n",
       " 'Telemana_Analysis.csv',\n",
       " 'India_State_Boundary.dbf',\n",
       " 'counselling_complaints.csv',\n",
       " 'India_State_Boundary.shp.xml',\n",
       " 'India_State_Boundary.shp']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('database')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "470dc19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_306181/244843486.py:17: DtypeWarning: Columns (25,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(self.survey_csv)\n",
      "/tmp/ipykernel_306181/244843486.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"Patient_age\"].fillna(df[\"Patient_age\"].mean(), inplace=True)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ST_NM'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'ST_NM'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 87\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     82\u001b[39m     builder = MapDataBuilder(\n\u001b[32m     83\u001b[39m         survey_csv=\u001b[33m\"\u001b[39m\u001b[33mdatabase/counselling_data.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     84\u001b[39m         states_geojson=\u001b[33m\"\u001b[39m\u001b[33mdatabase/INDIA_STATES.geojson\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     85\u001b[39m         output_json=\u001b[33m\"\u001b[39m\u001b[33mstatic/q6_map_.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     86\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     \u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 78\u001b[39m, in \u001b[36mMapDataBuilder.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 72\u001b[39m, in \u001b[36mMapDataBuilder.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msave\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     71\u001b[39m     os.makedirs(os.path.dirname(\u001b[38;5;28mself\u001b[39m.output_json), exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m.output_json, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     74\u001b[39m         json.dump(data, f, indent=\u001b[32m2\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mMapDataBuilder.build\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m     48\u001b[39m     survey_pct = \u001b[38;5;28mself\u001b[39m.load_and_prepare_survey()\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     gdf_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_states_geo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     merged = pd.merge(\n\u001b[32m     52\u001b[39m         survey_pct,\n\u001b[32m     53\u001b[39m         gdf_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m     56\u001b[39m         how=\u001b[33m\"\u001b[39m\u001b[33minner\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     57\u001b[39m     )\n\u001b[32m     59\u001b[39m     records: List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] = []\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36mMapDataBuilder.load_states_geo\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_states_geo\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> gpd.GeoDataFrame:\n\u001b[32m     43\u001b[39m     gdf = gpd.read_file(\u001b[38;5;28mself\u001b[39m.states_geojson)\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     gdf[\u001b[33m\"\u001b[39m\u001b[33mState_Name\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mgdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mST_NM\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.str.upper().str.strip()\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m gdf[[\u001b[33m\"\u001b[39m\u001b[33mState_Name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgeometry\u001b[39m\u001b[33m\"\u001b[39m]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/geopandas/geodataframe.py:1750\u001b[39m, in \u001b[36mGeoDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m   1745\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[33;03m    If the result is a column containing only 'geometry', return a\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[33;03m    GeoSeries. If it's a DataFrame with any columns of GeometryDtype,\u001b[39;00m\n\u001b[32m   1748\u001b[39m \u001b[33;03m    return a GeoDataFrame.\u001b[39;00m\n\u001b[32m   1749\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1751\u001b[39m     \u001b[38;5;66;03m# Custom logic to avoid waiting for pandas GH51895\u001b[39;00m\n\u001b[32m   1752\u001b[39m     \u001b[38;5;66;03m# result is not geometry dtype for multi-indexes\u001b[39;00m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1754\u001b[39m         pd.api.types.is_scalar(key)\n\u001b[32m   1755\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1758\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_geometry_type(result)\n\u001b[32m   1759\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'ST_NM'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "class MapDataBuilder:\n",
    "    def __init__(self,\n",
    "                 survey_csv: str = \"counselling_data.csv\",\n",
    "                 states_geojson: str = \"INDIA_STATES.geojson\",\n",
    "                 output_json: str = \"static/q6_map_.json\"):\n",
    "        self.survey_csv  = survey_csv\n",
    "        self.states_geojson = states_geojson\n",
    "        self.output_json = output_json\n",
    "\n",
    "    def load_and_prepare_survey(self) -> pd.DataFrame:\n",
    "        df = pd.read_csv(self.survey_csv)\n",
    "        df = df[[\"Patient_State\", \"patient â†’ age\"]].copy()\n",
    "        df.columns = [\"Patient_State\", \"Patient_age\"]\n",
    "\n",
    "        # fill missing\n",
    "        df[\"Patient_age\"].fillna(df[\"Patient_age\"].mean(), inplace=True)\n",
    "\n",
    "        # categorize\n",
    "        df[\"Age_Group\"] = df[\"Patient_age\"].apply(\n",
    "            lambda age: \"Children\" if age <= 20\n",
    "                        else \"Adults\" if age <= 60\n",
    "                        else \"Elders\"\n",
    "        )\n",
    "\n",
    "        pct = (\n",
    "            df.groupby([\"Patient_State\", \"Age_Group\"]).size()\n",
    "              .unstack(fill_value=0)\n",
    "              .pipe(lambda d: d.div(d.sum(axis=1), axis=0) * 100)\n",
    "              .reset_index()\n",
    "        )\n",
    "        for col in [\"Children\", \"Adults\", \"Elders\"]:\n",
    "            if col not in pct:\n",
    "                pct[col] = 0.0\n",
    "        return pct\n",
    "\n",
    "    def load_states_geo(self) -> gpd.GeoDataFrame:\n",
    "        gdf = gpd.read_file(self.states_geojson)\n",
    "        gdf[\"State_Name\"] = gdf[\"ST_NM\"].str.upper().str.strip()\n",
    "        return gdf[[\"State_Name\", \"geometry\"]]\n",
    "\n",
    "    def build(self) -> List[Dict[str, Any]]:\n",
    "        survey_pct = self.load_and_prepare_survey()\n",
    "        gdf_states = self.load_states_geo()\n",
    "\n",
    "        merged = pd.merge(\n",
    "            survey_pct,\n",
    "            gdf_states,\n",
    "            left_on=\"Patient_State\",\n",
    "            right_on=\"State_Name\",\n",
    "            how=\"inner\"\n",
    "        )\n",
    "\n",
    "        records: List[Dict[str, Any]] = []\n",
    "        for _, row in merged.iterrows():\n",
    "            records.append({\n",
    "                \"state\": row[\"State_Name\"],\n",
    "                \"geometry\": row[\"geometry\"].wkt,\n",
    "                \"Children\": round(row[\"Children\"], 6),\n",
    "                \"Adults\":   round(row[\"Adults\"],   6),\n",
    "                \"Elders\":   round(row[\"Elders\"],   6)\n",
    "            })\n",
    "        return records\n",
    "\n",
    "    def save(self):\n",
    "        os.makedirs(os.path.dirname(self.output_json), exist_ok=True)\n",
    "        data = self.build()\n",
    "        with open(self.output_json, \"w\") as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "        print(f\"✅ Saved map data to {self.output_json}\")\n",
    "\n",
    "    def run(self):\n",
    "        self.save()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    builder = MapDataBuilder(\n",
    "        survey_csv=\"database/counselling_data.csv\",\n",
    "        states_geojson=\"database/INDIA_STATES.geojson\",\n",
    "        output_json=\"static/q6_map_.json\"\n",
    "    )\n",
    "    builder.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "396ca838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['info.txt',\n",
       " 'Anonymized_Call_Handle_Data.csv',\n",
       " 'repeated_calls.csv',\n",
       " 'India_State_Boundary.prj',\n",
       " 'India_State_Boundary.sbn',\n",
       " 'INDIA_STATES.geojson',\n",
       " 'Call_not_picked.csv',\n",
       " 'India_State_Boundary.sbx',\n",
       " 'call_connected_issues.csv',\n",
       " 'counselling_data.csv',\n",
       " 'India_State_Boundary.cpg',\n",
       " 'India_State_Boundary.shx',\n",
       " 'Telemana_Analysis.csv',\n",
       " 'India_State_Boundary.dbf',\n",
       " 'counselling_complaints.csv',\n",
       " 'India_State_Boundary.shp.xml',\n",
       " 'India_State_Boundary.shp']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('database')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a7b98e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 21)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('database/counselling_complaints.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bf2bdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_306181/14657156.py:17: DtypeWarning: Columns (25,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(self.survey_csv)\n",
      "/tmp/ipykernel_306181/14657156.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"Patient_age\"].fillna(df[\"Patient_age\"].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Available columns in GeoJSON: ['STNAME', 'STCODE11', 'STNAME_SH', 'Shape_Length', 'Shape_Area', 'OBJECTID_1', 'OBJECTID', 'State_LGD', 'Shape_Leng', 'MaxSimpTol', 'MinSimpTol', 'geometry']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "❌ Could not find a suitable state name column in GeoJSON file.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 104\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     99\u001b[39m     builder = MapDataBuilder(\n\u001b[32m    100\u001b[39m         survey_csv=\u001b[33m\"\u001b[39m\u001b[33mdatabase/counselling_data.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    101\u001b[39m         states_geojson=\u001b[33m\"\u001b[39m\u001b[33mdatabase/INDIA_STATES.geojson\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    102\u001b[39m         output_json=\u001b[33m\"\u001b[39m\u001b[33mstatic/q6_map_.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    103\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 95\u001b[39m, in \u001b[36mMapDataBuilder.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 89\u001b[39m, in \u001b[36mMapDataBuilder.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msave\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     88\u001b[39m     os.makedirs(os.path.dirname(\u001b[38;5;28mself\u001b[39m.output_json), exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m.output_json, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     91\u001b[39m         json.dump(data, f, indent=\u001b[32m2\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mMapDataBuilder.build\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m     63\u001b[39m     survey_pct = \u001b[38;5;28mself\u001b[39m.load_and_prepare_survey()\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     gdf_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_states_geo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m     \u001b[38;5;66;03m# Merge survey data with geographic shapes\u001b[39;00m\n\u001b[32m     67\u001b[39m     merged = pd.merge(\n\u001b[32m     68\u001b[39m         survey_pct,\n\u001b[32m     69\u001b[39m         gdf_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m     72\u001b[39m         how=\u001b[33m\"\u001b[39m\u001b[33minner\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     73\u001b[39m     )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 58\u001b[39m, in \u001b[36mMapDataBuilder.load_states_geo\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m❌ Could not find a suitable state name column in GeoJSON file.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m gdf[[\u001b[33m\"\u001b[39m\u001b[33mState_Name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgeometry\u001b[39m\u001b[33m\"\u001b[39m]]\n",
      "\u001b[31mValueError\u001b[39m: ❌ Could not find a suitable state name column in GeoJSON file."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "class MapDataBuilder:\n",
    "    def __init__(self,\n",
    "                 survey_csv: str = \"counselling_data.csv\",\n",
    "                 states_geojson: str = \"INDIA_STATES.geojson\",\n",
    "                 output_json: str = \"static/q6_map_.json\"):\n",
    "        self.survey_csv = survey_csv\n",
    "        self.states_geojson = states_geojson\n",
    "        self.output_json = output_json\n",
    "\n",
    "    def load_and_prepare_survey(self) -> pd.DataFrame:\n",
    "        df = pd.read_csv(self.survey_csv)\n",
    "        df = df[[\"Patient_State\", \"patient â†’ age\"]].copy()\n",
    "        df.columns = [\"Patient_State\", \"Patient_age\"]\n",
    "\n",
    "        # Fill missing age values with mean\n",
    "        df[\"Patient_age\"].fillna(df[\"Patient_age\"].mean(), inplace=True)\n",
    "\n",
    "        # Categorize by age group\n",
    "        df[\"Age_Group\"] = df[\"Patient_age\"].apply(\n",
    "            lambda age: \"Children\" if age <= 20\n",
    "                        else \"Adults\" if age <= 60\n",
    "                        else \"Elders\"\n",
    "        )\n",
    "\n",
    "        # Calculate percentage per age group per state\n",
    "        pct = (\n",
    "            df.groupby([\"Patient_State\", \"Age_Group\"]).size()\n",
    "              .unstack(fill_value=0)\n",
    "              .pipe(lambda d: d.div(d.sum(axis=1), axis=0) * 100)\n",
    "              .reset_index()\n",
    "        )\n",
    "\n",
    "        # Ensure all expected columns are present\n",
    "        for col in [\"Children\", \"Adults\", \"Elders\"]:\n",
    "            if col not in pct:\n",
    "                pct[col] = 0.0\n",
    "\n",
    "        return pct\n",
    "\n",
    "    def load_states_geo(self) -> gpd.GeoDataFrame:\n",
    "        gdf = gpd.read_file(self.states_geojson)\n",
    "\n",
    "        # Print columns to help debug if something goes wrong\n",
    "        print(\"🧾 Available columns in GeoJSON:\", gdf.columns.tolist())\n",
    "\n",
    "        # Try known column names for state\n",
    "        for possible_col in [\"ST_NM\", \"state\", \"STATE_NAME\", \"NAME_1\", \"NAME\"]:\n",
    "            if possible_col in gdf.columns:\n",
    "                gdf[\"State_Name\"] = gdf[possible_col].str.upper().str.strip()\n",
    "                break\n",
    "        else:\n",
    "            raise ValueError(\"❌ Could not find a suitable state name column in GeoJSON file.\")\n",
    "\n",
    "        return gdf[[\"State_Name\", \"geometry\"]]\n",
    "\n",
    "    def build(self) -> List[Dict[str, Any]]:\n",
    "        survey_pct = self.load_and_prepare_survey()\n",
    "        gdf_states = self.load_states_geo()\n",
    "\n",
    "        # Merge survey data with geographic shapes\n",
    "        merged = pd.merge(\n",
    "            survey_pct,\n",
    "            gdf_states,\n",
    "            left_on=\"Patient_State\",\n",
    "            right_on=\"State_Name\",\n",
    "            how=\"inner\"\n",
    "        )\n",
    "\n",
    "        # Prepare JSON records\n",
    "        records: List[Dict[str, Any]] = []\n",
    "        for _, row in merged.iterrows():\n",
    "            records.append({\n",
    "                \"state\": row[\"State_Name\"],\n",
    "                \"geometry\": row[\"geometry\"].wkt,\n",
    "                \"Children\": round(row[\"Children\"], 6),\n",
    "                \"Adults\": round(row[\"Adults\"], 6),\n",
    "                \"Elders\": round(row[\"Elders\"], 6)\n",
    "            })\n",
    "        return records\n",
    "\n",
    "    def save(self):\n",
    "        os.makedirs(os.path.dirname(self.output_json), exist_ok=True)\n",
    "        data = self.build()\n",
    "        with open(self.output_json, \"w\") as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "        print(f\"✅ Saved map data to {self.output_json}\")\n",
    "\n",
    "    def run(self):\n",
    "        self.save()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    builder = MapDataBuilder(\n",
    "        survey_csv=\"database/counselling_data.csv\",\n",
    "        states_geojson=\"database/INDIA_STATES.geojson\",\n",
    "        output_json=\"static/q6_map_.json\"\n",
    "    )\n",
    "    builder.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
